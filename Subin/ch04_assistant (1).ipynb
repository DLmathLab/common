{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d17b8dfe-7e3a-4d2f-957d-b5a67529c8a2",
      "metadata": {
        "id": "d17b8dfe-7e3a-4d2f-957d-b5a67529c8a2",
        "outputId": "357dfdb7-5ade-46e9-ca93-4847953de06b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-28 14:45:43.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.148 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.148 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-28 14:45:43.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "##### ê¸°ë³¸ ì •ë³´ ì…ë ¥ ####\n",
        "# Streamlit íŒ¨í‚¤ì§€ ì¶”ê°€\n",
        "import streamlit as st # streamlit : ì›¹ì•±ì„ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬\n",
        "\n",
        "# OpenAI íŒ¨í‚¤ì§€ ì¶”ê°€\n",
        "from openai import OpenAI # ChatGPT, Whisper, TTS API í˜¸ì¶œ\n",
        "\n",
        "# ì±„íŒ… ì‹œê°„ì„ ê¸°ë¡í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€\n",
        "from datetime import datetime\n",
        "\n",
        "# ìŒì„± ë…¹ìŒì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€\n",
        "from audiorecorder import audiorecorder # for ì‚¬ìš©ì ìŒì„± ì…ë ¥ ë°›ê¸°\n",
        "\n",
        "# íŒŒì´ì¬ ê¸°ë³¸ íŒ¨í‚¤ì§€\n",
        "import os\n",
        "import numpy as np\n",
        "import base64\n",
        "\n",
        "##### ê¸°ëŠ¥ êµ¬í˜„ í•¨ìˆ˜ #####\n",
        "def STT(audio, client): # speech to text\n",
        "    # Whisper ëª¨ë¸ì´ íŒŒì¼ í˜•íƒœë¡œ ì…ë ¥ì„ ë°›ìœ¼ë¯€ë¡œ input.mp3 íŒŒì¼ì´ë€ ì´ë¦„ìœ¼ë¡œ ìŒì„± íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    filename='input.mp3'\n",
        "    wav_file = open(filename, \"wb\")\n",
        "    wav_file.write(audio.export().read()) # ë…¹ìŒëœ ìŒì„±íŒŒì¼ì„ mp3ë¡œ ì €ì¥\n",
        "    wav_file.close()\n",
        "\n",
        "    # ìŒì„± íŒŒì¼ ì—´ê¸°\n",
        "    audio_file = open(filename, \"rb\")\n",
        "    # Whisper ëª¨ë¸ì„ í™œìš©í•´ í…ìŠ¤íŠ¸ ì–»ê¸°\n",
        "    try:\n",
        "\n",
        "        # openai ì˜ whisper API ë¥¼ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "        transcript = client.audio.transcriptions.create(\n",
        "        model=\"whisper-1\",\n",
        "        file=audio_file,\n",
        "        response_format=\"text\"\n",
        "        )\n",
        "\n",
        "        # Whisperë¡œ TTSê°€ ëë‚¬ìœ¼ë‹ˆ ì´ì œ mp3 íŒŒì¼ì„ ë‹¤ì‹œ ì‚­ì œí•©ë‹ˆë‹¤.\n",
        "        audio_file.close()\n",
        "        os.remove(filename) # ë‹¤ ì“´ íŒŒì¼ì€ ë‹«ê³  ì‚­ì œê¹Œì§€\n",
        "    except:\n",
        "        transcript = 'ì—¬ëŸ¬ë¶„ë“¤ì˜ Key ê°’'\n",
        "    return transcript # ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ê¸°ë³¸ ë¬¸êµ¬ë¥¼ ì¶œë ¥\n",
        "\n",
        "def TTS(response): # gpt ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë§Œë“¤ê¸°\n",
        "    # TTSë¥¼ í™œìš©í•˜ì—¬ ë§Œë“  ìŒì„±ì„ íŒŒì¼ë¡œ ì €ì¥.\n",
        "    with client.audio.speech.with_streaming_response.create( # ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹ìœ¼ë¡œ ë°›ì•„ì˜´\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",\n",
        "        input=response,\n",
        "    ) as response:\n",
        "        filename = \"output.mp3\"\n",
        "        response.stream_to_file(filename)\n",
        "\n",
        "    # ì €ì¥í•œ ìŒì„± íŒŒì¼ ìë™ ì¬ìƒ\n",
        "    with open(filename, \"rb\") as f: # ì €ì¥ëœ mp3ë¥¼ ì½ê³ , base64ë¡œ ì¸ì½”ë”©\n",
        "        data = f.read()\n",
        "        b64 = base64.b64encode(data).decode()\n",
        "\n",
        "        # TTSë¥¼ í†µí•´ ìƒì„±ëœ ì‚¬ëŒ ëª©ì†Œë¦¬ì˜ ìŒì›íŒŒì¼ì„ ì¬ìƒì„ í•˜ë ¤ë©´\n",
        "        # streamlit ì˜ audio ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "        # í•˜ì§€ë§Œ audio ë©”ì„œë“œëŠ” ì¬ìƒ ë²„íŠ¼ì„ í´ë¦­í•´ì•¼ë§Œ ì¬ìƒì´ ë©ë‹ˆë‹¤.\n",
        "        # ë”°ë¼ì„œ ìš°ë¦¬ê°€ ì§ˆë¬¸ì„ í•˜ë©´ ë”°ë¡œ ë‹µë³€ì„ ë“£ëŠ” ë²„íŠ¼ í´ë¦­ ì—†ì´ ìƒì„±ì´ ì™„ë£Œë˜ë©´\n",
        "        # ìë™ ì¬ìƒë  ìˆ˜ ìˆë„ë¡ ë³µì¡í•œ ì½”ë“œë¡œ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "        # HTML ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ìŒì›ì„ ì¬ìƒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì˜€ê³ \n",
        "        # streamlit ì•ˆì—ì„œ HTML ë¬¸ë²• êµ¬í˜„ì— ì‚¬ìš©ë˜ëŠ” st.markdown() ì„ í™œìš©í•˜ì—¬ ì‹¤í–‰ì„ í•©ë‹ˆë‹¤.\n",
        "\n",
        "        # ì¦‰, audio autoplayë¥¼ ì‘ì„±í•´ì„œ ìŒì„±ì„ ìë™ ì¬ìƒí•  ìˆ˜ ìˆë„ë¡ êµ¬í˜„í•¨\n",
        "\n",
        "        md = f\"\"\"\n",
        "            <audio autoplay=\"True\">\n",
        "            <source src=\"data:audio/mp3;base64,{b64}\" type=\"audio/mp3\">\n",
        "            </audio>\n",
        "            \"\"\"\n",
        "        st.markdown(md, unsafe_allow_html=True,)\n",
        "    # í´ë”ì— ë‚¨ì§€ ì•Šë„ë¡ íŒŒì¼ ì‚­ì œ\n",
        "    os.remove(filename)\n",
        "\n",
        "# ChatGPTê°€ ë‹µë³€ì„ ì‘ì„±\n",
        "# messageë¦¬ìŠ¤íŠ¸ë¥¼ gptì—ê²Œ í”„ë¡¬í”„íŠ¸ë¡œ ì „ë‹¬í•˜ê³  ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜\n",
        "def ask_gpt(prompt, client):\n",
        "    response = client.chat.completions.create(model='gpt-3.5-turbo', messages=prompt)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "### streamlitì„ ì´ìš©í•´ì„œ ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ###\n",
        "# ìœ„ì—ì„œ ì–¸ê¸‰í•œ í•¨ìˆ˜ STT(Whipser), TTS, ChatGPTë¥¼ ì´ìš©í•˜ì—¬ ìŒì„± ë¹„ì„œ ì½”ë“œë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.\n",
        "# ì›¹ í˜ì´ì§€ ì´ë¦„ê³¼ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "st.set_page_config(\n",
        "    page_title=\"ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨ğŸ”Š\",\n",
        "    layout=\"wide\")\n",
        "\n",
        "# session state 3ê°œ ì´ˆê¸°í™”\n",
        "# st.session_state[\"chat\"] : ì‚¬ìš©ìì™€ ìŒì„±ë¹„ì„œì˜ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ì—¬ ì±„íŒ…ì°½ ì‹œê°í™”ì— ì‚¬ìš©\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "# st.session_state[\"check_audio\"] : í”„ë¡œê·¸ë¨ì´ ì¬ì‹¤í–‰ ë  ë•Œë§ˆë‹¤ ì´ì „ ë…¹ìŒíŒŒì¼ ì •ë³´ê°€ ë²„í¼ì—\n",
        "# ë‚¨ì•„ìˆì–´ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì´ì „ ë…¹ìŒíŒŒì¼ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤\n",
        "if \"check_audio\" not in st.session_state:\n",
        "    st.session_state[\"check_audio\"] = []\n",
        "\n",
        "# st.session_state[\"messages\"] : GPT APIì— ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°ˆ í”„ë¡¬í”„íŠ¸ ì–‘ì‹. ì´ì „ ì§ˆë¬¸ ë° ë‹µë³€ì„ ëˆ„ì í•˜ì—¬ ì €ì¥.\n",
        "# ì¦‰, gptì— ì „ë‹¬í•œ ì „ì²´ ëŒ€í™”ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì €ì¥\n",
        "# ì²˜ìŒì—ëŠ” system ë©”ì„¸ì§€ë¡œ ì‹œì‘\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": 'You are a thoughtful assistant. Respond to all input in 25 words and answer in korean'}]\n",
        "\n",
        "### ìƒë‹¨ ui êµ¬ì„± ###\n",
        "# ì´ë¯¸ì§€, ì œëª©, ì„¤ëª… í‘œì‹œ\n",
        "# ì œëª©\n",
        "st.image('ai.png', width=200)\n",
        "st.header('ë‚˜ë§Œì˜ ì¸ê³µì§€ëŠ¥ ë¹„ì„œ ğŸ”Š')\n",
        "# êµ¬ë¶„ì„ \n",
        "st.markdown('---')\n",
        "st.subheader('ëª¨ë¥´ëŠ” ì§ˆë¬¸ì„ í•˜ë©´ ë‹µë³€í•´ì¤„ê±°ì—ìš”.ğŸ¤')\n",
        "\n",
        "\n",
        "# OpenAI API í‚¤ ì§€ì •í•˜ê¸°\n",
        "client = OpenAI(\n",
        "        api_key = \"ì—¬ëŸ¬ë¶„ë“¤ì˜ Key ê°’\"\n",
        ")\n",
        "# ìŒì„± ì…ë ¥ í™•ì¸ Flag\n",
        "flag_start = False\n",
        "\n",
        "### ì™¼ìª½ ui êµ¬ì„± ###\n",
        "# ê¸°ëŠ¥ êµ¬í˜„ ê³µê°„\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    # ì™¼ìª½ ê³µê°„ ì‘ì„±\n",
        "    # ìŒì„± ë…¹ìŒ ì•„ì´ì½˜ ì¶”ê°€\n",
        "    audio = audiorecorder(\"ì§ˆë¬¸\", \"ë…¹ìŒì¤‘...\")\n",
        "    if len(audio) > 0 and not np.array_equal(audio, st.session_state[\"check_audio\"]):\n",
        "        # ìŒì„± ì¬ìƒ\n",
        "        st.audio(audio.export().read())\n",
        "\n",
        "        # ìŒì› íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "        question = STT(audio, client)\n",
        "\n",
        "        # ì±„íŒ… ì‹œê°í™”ë¥¼ ìœ„í•œ ì§ˆë¬¸ ë‚´ìš© ì €ì¥\n",
        "        now = datetime.now().strftime(\"%H:%M\")\n",
        "        st.session_state[\"chat\"] = st.session_state[\"chat\"]+ [(\"user\", now, question)]\n",
        "        # GPT ëª¨ë¸ì— ë„£ì„ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•´ ì§ˆë¬¸ ì €ì¥. ì´ë•Œ ê¸°ì¡´ ë‚´ìš© ëˆ„ì .\n",
        "        st.session_state[\"messages\"] = st.session_state[\"messages\"]+ [{\"role\": \"user\", \"content\": question}]\n",
        "        # audio ë²„í¼ í™•ì¸ì„ ìœ„í•´ í˜„ ì‹œì  ì˜¤ë””ì˜¤ ì •ë³´ ì €ì¥\n",
        "        st.session_state[\"check_audio\"] = audio\n",
        "        flag_start=True\n",
        "\n",
        "### ì˜¤ë¥¸ìª½ ui êµ¬ì„± ###\n",
        "with col2:\n",
        "    # ì˜¤ë¥¸ìª½ ê³µê°„ ì‘ì„±\n",
        "    st.subheader('ëŒ€í™”ê¸°ë¡ âŒ¨')\n",
        "    if flag_start:\n",
        "\n",
        "        # ChatGPTì—ê²Œ ë‹µë³€ ì–»ê¸°\n",
        "        response = ask_gpt(st.session_state[\"messages\"], client)\n",
        "\n",
        "        # GPT ëª¨ë¸ì— ë„£ì„ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•´ ë‹µë³€ ë‚´ìš© ì €ì¥\n",
        "        st.session_state[\"messages\"] = st.session_state[\"messages\"]+ [{\"role\": \"assistant\", \"content\": response}]\n",
        "\n",
        "        # ì±„íŒ… ì‹œê°í™”ë¥¼ ìœ„í•œ ë‹µë³€ ë‚´ìš© ì €ì¥\n",
        "        now = datetime.now().strftime(\"%H:%M\")\n",
        "        st.session_state[\"chat\"] = st.session_state[\"chat\"]+ [(\"bot\",now, response)]\n",
        "\n",
        "        # ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ì‹œê°í™” í•˜ê¸°\n",
        "        for sender, time, message in st.session_state[\"chat\"]:\n",
        "            if sender == \"user\":\n",
        "                st.write(f'<div style=\"display:flex;align-items:center;\"><div style=\"background-color:#007AFF;color:white;border-radius:12px;padding:8px 12px;margin-right:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "                st.write(\"\")\n",
        "            else:\n",
        "                st.write(f'<div style=\"display:flex;align-items:center;justify-content:flex-end;\"><div style=\"background-color:lightgray;border-radius:12px;padding:8px 12px;margin-left:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "                st.write(\"\")\n",
        "\n",
        "        # TTS ë¥¼ í™œìš©í•˜ì—¬ ìŒì„± íŒŒì¼ ìƒì„± ë° ì¬ìƒ\n",
        "        TTS(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# base64ë€?\n",
        "ì´ì§„(binary) ë°ì´í„°ë¥¼ ë¬¸ì(text)ë¡œ ë°”ê¾¸ëŠ” ë°©ë²•\n",
        "\n",
        "## why?\n",
        "ìš°ë¦¬ê°€ í”íˆ ë‹¤ë£¨ëŠ” ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë™ì˜ìƒ, zip íŒŒì¼ ë“±ì€ binary ë°ì´í„°\n",
        "í•˜ì§€ë§Œ ì›¹ì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ **ë¬¸ì ê¸°ë°˜(HTML, JS, CSS)**ìœ¼ë¡œ ì‘ë™\n",
        "\n",
        "â¡ ê·¸ë˜ì„œ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë¬¸ìë¡œ ë³€í™˜í•´ì„œ\n",
        "\n",
        "â¡ ì›¹ì—ì„œ ì§ì ‘ ë„£ê±°ë‚˜ ì „ì†¡í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²Œ base64 ì¸ì½”ë”©"
      ],
      "metadata": {
        "id": "Om3ClT3d_dWa"
      },
      "id": "Om3ClT3d_dWa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d92da27-9d08-48e8-b422-f8910353ee30",
      "metadata": {
        "id": "0d92da27-9d08-48e8-b422-f8910353ee30"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}