{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 정보 입력\n",
    "- pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 지정하여 클라이언트 선언하기\n",
    "OPENAI_API_KEY=\"API_KEY\"\n",
    "\n",
    "\n",
    "client = openai.OpenAI(api_key = '여기에 API 키를 넣어주세요'\n",
    "# client = openai.OpenAI(api_key = \"여기에 API 키를 넣어주세요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id (string): 채팅 완성에 대한 고유 식별자입니다. 모델에 의해 생성된 각 완성은 구별되는 ID를 가지며, 특정 응답을 추적하거나 참조하는 데 유용할 수 있습니다.\n",
    "\n",
    "- choices (array): 모델이 제공하는 다양한 응답들을 포함하는 채팅 완성 선택 목록입니다. 요청의 'n' 매개변수가 1보다 크면 이 배열에는 모델이 생성한 여러 가지 가능한 완성이 포함될 수 있습니다.이 배열 내의 각 선택에는 완성의 텍스트와 기타 관련 데이터와 같은 추가 속성들이 포함됩니다.\n",
    "\n",
    "- created (integer): 채팅 완성이 생성된 시점의 유닉스 타임스탬프(초 단위)를 나타냅니다. 이는 응답이 생성된 정확한 시간을 결정하는 데 도움이 됩니다.\n",
    "\n",
    "- model (string): 채팅 완성을 생성하는 데 사용된 특정 모델을 지정합니다. 다른 모델들은 다양한 능력이나 스타일을 가지고 있을 수 있으며, 이 필드는 응답을 위해 사용된 모델을 나타냅니다.\n",
    "\n",
    "- system_fingerprint (string): 이 지문은 모델이 실행되는 백엔드 구성을 나타냅니다. 반응의 결정론에 영향을 줄 수 있는 백엔드 변경 사항을 이해하기 위해 'seed' 요청 매개변수와 함께 사용될 수 있습니다.\n",
    "\n",
    "- object (string): API에서 반환하는 객체의 유형을 나타내는 필드입니다. 채팅 완성의 경우에는 항상 'chat.completion'이 될 것이며, 응답 객체의 성격을 확인합니다.\n",
    "\n",
    "- usage (object): 완성 요청에 대한 사용 통계를 포함하는 객체입니다. 응답 생성에 사용된 토큰 수와 같은 정보를 포함할 수 있습니다. 이는 API 사용을 추적하고 요청과 관련된 비용을 이해하는 데 특히 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B5nRBXvlKQyXAXq86ndP6B14gEyQl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1. Preheat your oven to 475°F (245°C).\\n\\n2. Prepare your pizza dough by either making it from scratch or using a store-bought dough. Roll out the dough on a floured surface to your desired thickness.\\n\\n3. Place the rolled-out dough on a pizza stone or baking sheet lined with parchment paper.\\n\\n4. Spread a layer of pizza sauce over the dough, leaving a small border around the edges.\\n\\n5. Add your desired toppings such as cheese, vegetables, meats, and herbs.\\n\\n6. Bake the pizza in the preheated oven for about 12-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\\n\\n7. Remove the pizza from the oven and let it cool for a few minutes before slicing and serving.\\n\\n8. Enjoy your homemade pizza!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740721377, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=168, prompt_tokens=14, total_tokens=182, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Tell me how to make a pizza\"}])\n",
    "\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Preheat your oven to 475°F (245°C).\n",
      "\n",
      "2. Prepare your pizza dough by either making it from scratch or using a store-bought dough. Roll out the dough on a floured surface to your desired thickness.\n",
      "\n",
      "3. Place the rolled-out dough on a pizza stone or baking sheet lined with parchment paper.\n",
      "\n",
      "4. Spread a layer of pizza sauce over the dough, leaving a small border around the edges.\n",
      "\n",
      "5. Add your desired toppings such as cheese, vegetables, meats, and herbs.\n",
      "\n",
      "6. Bake the pizza in the preheated oven for about 12-15 minutes, or until the crust is golden brown and the cheese is melted and bubbly.\n",
      "\n",
      "7. Remove the pizza from the oven and let it cool for a few minutes before slicing and serving.\n",
      "\n",
      "8. Enjoy your homemade pizza!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 요금 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1k 토큰 당 비용\n",
    "\n",
    "|Model|Input|Output|\n",
    "|---|---|---|\n",
    "|gpt-4|$0.03|$0.06|\n",
    "|gpt-4-32k|$0.06|$0.12|\n",
    "|gpt-4-turbo|$0.01|$0.03|\n",
    "|gpt-3.5-turbo|$0.001|$0.002|\n",
    "|gpt-3.5-turbo-instruct|$0.0015|$0.002|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=168, prompt_tokens=14, total_tokens=182, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 소모 비용 : 0.45669400000000004 원\n"
     ]
    }
   ],
   "source": [
    "total_bill_USD = (response.usage.completion_tokens*0.002 +response.usage.prompt_tokens*0.001)/1000\n",
    "# 23.11.27 기준 환율 1USD = 1304.84 KRW\n",
    "total_bill_KRW = total_bill_USD*1304.84\n",
    "print(\"총 소모 비용 : {} 원\".format(total_bill_KRW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 역할 부여하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Dodgers won the 2020 World Series.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    " model=\"gpt-3.5-turbo\",\n",
    " messages=[\n",
    " {\"role\": \"system\", \"content\" : \"You must only answer users' questions in English. This must be honored. You must only answer in English.\"},\n",
    " {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}\n",
    " ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who won the World Series in 2020?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a translator that translates users' inputs. If the input is in Korean, it must be translated into English. This must be strictly adhered to.\"},\n",
    "{\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
    " )\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이어서 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at a neutral site due to the pandemic. The games were held at Globe Life Field in Arlington, Texas.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
